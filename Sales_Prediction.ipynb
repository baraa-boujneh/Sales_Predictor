{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/baraa-boujneh/Sales_Predictor/blob/master/Sales_Prediction.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**1. Importing Libraries**"
      ],
      "metadata": {
        "id": "p9g8lTCYMxrB"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install np_utils"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DbvjHx1KQqgg",
        "outputId": "266fda9a-b9a9-4ecf-c978-20e583913540"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting np_utils\n",
            "  Downloading np_utils-0.6.0.tar.gz (61 kB)\n",
            "\u001b[?25l     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/62.0 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K     \u001b[91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[91m╸\u001b[0m \u001b[32m61.4/62.0 kB\u001b[0m \u001b[31m2.1 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\r\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m62.0/62.0 kB\u001b[0m \u001b[31m1.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: numpy>=1.0 in /usr/local/lib/python3.10/dist-packages (from np_utils) (1.25.2)\n",
            "Building wheels for collected packages: np_utils\n",
            "  Building wheel for np_utils (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for np_utils: filename=np_utils-0.6.0-py3-none-any.whl size=56441 sha256=40a7c7e5839c8f226d618e20846137ff9f02798f95bf2e3a98b6b3698ff159d2\n",
            "  Stored in directory: /root/.cache/pip/wheels/b6/c7/50/2307607f44366dd021209f660045f8d51cb976514d30be7cc7\n",
            "Successfully built np_utils\n",
            "Installing collected packages: np_utils\n",
            "Successfully installed np_utils-0.6.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "fxAXlsDNMrND"
      },
      "outputs": [],
      "source": [
        "    # EDA Libraries:\n",
        "    import pandas as pd\n",
        "    import numpy as np\n",
        "\n",
        "    import matplotlib.colors as col\n",
        "    from mpl_toolkits.mplot3d import Axes3D\n",
        "    import matplotlib.pyplot as plt\n",
        "    import seaborn as sns\n",
        "    %matplotlib inline\n",
        "\n",
        "    import datetime\n",
        "    from pathlib import Path\n",
        "    import random\n",
        "\n",
        "    # Scikit-Learn models:\n",
        "\n",
        "    from sklearn.preprocessing import MinMaxScaler\n",
        "    from sklearn.linear_model import LinearRegression\n",
        "    from sklearn.metrics import mean_squared_error, mean_absolute_error, r2_score\n",
        "    from sklearn.ensemble import RandomForestRegressor\n",
        "    from xgboost.sklearn import XGBRegressor\n",
        "    from sklearn.model_selection import KFold, cross_val_score, train_test_split\n",
        "\n",
        "    # LSTM:\n",
        "\n",
        "    import keras\n",
        "    from keras.layers import Dense\n",
        "    from keras.models import Sequential\n",
        "    from keras.callbacks import EarlyStopping\n",
        "    import np_utils\n",
        "    from keras.layers import LSTM\n",
        "\n",
        "\n",
        "    # ARIMA Model:\n",
        "\n",
        "    import statsmodels.tsa.api as smt\n",
        "    import statsmodels.api as sm\n",
        "    from statsmodels.tools.eval_measures import rmse\n",
        "\n",
        "\n",
        "    import pickle\n",
        "    import warnings"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**2. Loading and Exploring the Data set**"
      ],
      "metadata": {
        "id": "3weCUYFANU68"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "    from google.colab import drive\n",
        "    drive.mount('/content/drive')"
      ],
      "metadata": {
        "id": "cVxk7FC4PrHM",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "28d948a8-a33b-44be-ae5e-331e9f8adf86"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "    warnings.filterwarnings(\"ignore\", category=FutureWarning)\n",
        "    dataset = pd.read_csv('/content/drive/MyDrive/Sales_Prediction_res/train.csv')\n",
        "    df_ds = dataset.copy()\n",
        "    df_ds.head()\n",
        "    df_ds.info()"
      ],
      "metadata": {
        "id": "zdSSgxAlNYIy",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 373
        },
        "outputId": "1070a6ff-3a8b-46fe-a729-c2cbb0f924ec"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "FileNotFoundError",
          "evalue": "[Errno 2] No such file or directory: '/content/drive/MyDrive/Sales_Prediction_res/train.csv'",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-8-924f5c30a1cd>\u001b[0m in \u001b[0;36m<cell line: 2>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mwarnings\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfilterwarnings\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"ignore\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcategory\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mFutureWarning\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mdataset\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread_csv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'/content/drive/MyDrive/Sales_Prediction_res/train.csv'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0mdf_ds\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdataset\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcopy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mdf_ds\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhead\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mdf_ds\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minfo\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pandas/util/_decorators.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    209\u001b[0m                 \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    210\u001b[0m                     \u001b[0mkwargs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mnew_arg_name\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnew_arg_value\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 211\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    212\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    213\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mcast\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mF\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mwrapper\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pandas/util/_decorators.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    329\u001b[0m                     \u001b[0mstacklevel\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfind_stack_level\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    330\u001b[0m                 )\n\u001b[0;32m--> 331\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    332\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    333\u001b[0m         \u001b[0;31m# error: \"Callable[[VarArg(Any), KwArg(Any)], Any]\" has no\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pandas/io/parsers/readers.py\u001b[0m in \u001b[0;36mread_csv\u001b[0;34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, squeeze, prefix, mangle_dupe_cols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, skipfooter, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, dayfirst, cache_dates, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, doublequote, escapechar, comment, encoding, encoding_errors, dialect, error_bad_lines, warn_bad_lines, on_bad_lines, delim_whitespace, low_memory, memory_map, float_precision, storage_options)\u001b[0m\n\u001b[1;32m    948\u001b[0m     \u001b[0mkwds\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkwds_defaults\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    949\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 950\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0m_read\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    951\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    952\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pandas/io/parsers/readers.py\u001b[0m in \u001b[0;36m_read\u001b[0;34m(filepath_or_buffer, kwds)\u001b[0m\n\u001b[1;32m    603\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    604\u001b[0m     \u001b[0;31m# Create the parser.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 605\u001b[0;31m     \u001b[0mparser\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mTextFileReader\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    606\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    607\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mchunksize\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0miterator\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pandas/io/parsers/readers.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, f, engine, **kwds)\u001b[0m\n\u001b[1;32m   1440\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1441\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhandles\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mIOHandles\u001b[0m \u001b[0;34m|\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1442\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_engine\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_make_engine\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mengine\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1443\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1444\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mclose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pandas/io/parsers/readers.py\u001b[0m in \u001b[0;36m_make_engine\u001b[0;34m(self, f, engine)\u001b[0m\n\u001b[1;32m   1733\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0;34m\"b\"\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mmode\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1734\u001b[0m                     \u001b[0mmode\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;34m\"b\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1735\u001b[0;31m             self.handles = get_handle(\n\u001b[0m\u001b[1;32m   1736\u001b[0m                 \u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1737\u001b[0m                 \u001b[0mmode\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pandas/io/common.py\u001b[0m in \u001b[0;36mget_handle\u001b[0;34m(path_or_buf, mode, encoding, compression, memory_map, is_text, errors, storage_options)\u001b[0m\n\u001b[1;32m    854\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mioargs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mencoding\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0;34m\"b\"\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mioargs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmode\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    855\u001b[0m             \u001b[0;31m# Encoding\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 856\u001b[0;31m             handle = open(\n\u001b[0m\u001b[1;32m    857\u001b[0m                 \u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    858\u001b[0m                 \u001b[0mioargs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmode\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: '/content/drive/MyDrive/Sales_Prediction_res/train.csv'"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "id": "GiUpGOBHIf3K",
        "outputId": "bd606b30-da74-42e0-ddae-2fb35a7f647c",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**3.Data preprocessing**"
      ],
      "metadata": {
        "id": "4eGlBox7EXAA"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#axis=1 means that we will go through each row and delete the columns related to store and item\n",
        "df_ds=df_ds.drop(['store','item'],axis=1)\n",
        "#converting date from object datatype to dateTime datatype\n",
        "df_ds['date']=pd.to_datetime(df_ds['date'])\n",
        "df_ds.head()\n"
      ],
      "metadata": {
        "id": "Sr_IG5Y6U5NT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df_ds['date']=df_ds['date'].dt.to_period(\"M\")\n",
        "monthly_sales = df_ds.groupby('date').sum().reset_index()\n",
        "monthly_sales.info()\n",
        "monthly_sales.head()"
      ],
      "metadata": {
        "id": "MZdg9HjpYb3A"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "monthly_sales['date']=monthly_sales['date'].dt.to_timestamp()\n",
        "monthly_sales.info()\n",
        "monthly_sales.head(10)"
      ],
      "metadata": {
        "id": "uVqInd0CRQRj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Visualization**"
      ],
      "metadata": {
        "id": "W4M8YrCBc8ko"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "plt.figure(figsize=(15,5))\n",
        "plt.plot(monthly_sales['date'],monthly_sales['sales'])\n",
        "plt.xlabel(\"Date\")\n",
        "plt.ylabel(\"Sales\")\n",
        "plt.title(\"monthly customer sales\")\n",
        "plt.show\n"
      ],
      "metadata": {
        "id": "Leq4cEPLVIUP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**call the difference on the sales columns t make the sales data stationary**"
      ],
      "metadata": {
        "id": "0WAYRkfGnP80"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "monthly_sales['sales-diff']=monthly_sales['sales'].diff()\n",
        "monthly_sales=monthly_sales.dropna()\n",
        "monthly_sales"
      ],
      "metadata": {
        "id": "hgtP93Mmo4nE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Visualization**"
      ],
      "metadata": {
        "id": "-NY9tw4OsWqp"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "plt.figure(figsize=(15,5))\n",
        "plt.plot(monthly_sales['date'],monthly_sales['sales-diff'])\n",
        "plt.xlabel(\"Date\")\n",
        "plt.ylabel(\"Sales\")\n",
        "plt.title(\"monthly customer sales difference\")\n",
        "plt.show\n"
      ],
      "metadata": {
        "id": "V5xKw0HmscvN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Dropping off sales and date**"
      ],
      "metadata": {
        "id": "VLJerj8ZwlZV"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "supervised_data=monthly_sales.drop(['date','sales'], axis=1)\n",
        "supervised_data"
      ],
      "metadata": {
        "id": "el5NB45HB3H-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**preparing the supervised data**"
      ],
      "metadata": {
        "id": "p0VRJJjkCHbl"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "for i in range(1,13):\n",
        "  col_name='month_'+str(i)\n",
        "  supervised_data[col_name]=supervised_data['sales-diff'].shift(i)\n",
        "supervised_data=supervised_data.dropna().reset_index(drop=True)\n",
        "supervised_data"
      ],
      "metadata": {
        "id": "aStcchNrCLQI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Split the data into Train and Test**"
      ],
      "metadata": {
        "id": "6nzd7MoSFzEQ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "train_data=supervised_data[:-12]\n",
        "test_data=supervised_data[-12:]\n",
        "print(\"Train Data Shape: \", train_data.shape)\n",
        "print(\"Test Data Shape: \",test_data.shape)"
      ],
      "metadata": {
        "id": "j87fL7XFF9P1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "scaler = MinMaxScaler(feature_range=(-1,1))\n",
        "scaler.fit(train_data)\n",
        "train_data= scaler.transform(train_data)\n",
        "test_data= scaler.transform(test_data)\n"
      ],
      "metadata": {
        "id": "ZQZ4GlI-L9d-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X_train, y_train= train_data[:,1:],train_data[:,0]\n",
        "X_test, y_test = test_data[:,1:], test_data[:,0]\n",
        "y_train=y_train.ravel()\n",
        "y_test=y_test.ravel()\n",
        "print(\"X_train shape: \", X_train.shape)\n",
        "print(\"y_train shape: \", y_train.shape)\n",
        "print(\"X_Test shape: \", X_test.shape)\n",
        "print(\"y_Test shape: \", y_test.shape)"
      ],
      "metadata": {
        "id": "yQukpRaaMiM6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Make prediction data frame to merge the predicted sales prices of all trained algs**"
      ],
      "metadata": {
        "id": "lQhy1aCBOmNt"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "sales_dates=monthly_sales['date'][-12:].reset_index(drop=True)\n",
        "predict_df = pd.DataFrame(sales_dates)"
      ],
      "metadata": {
        "id": "3L3nG8O1OyUb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "act_sales = monthly_sales['sales'][-13:].to_list()\n",
        "print(act_sales)"
      ],
      "metadata": {
        "id": "mdAUBH-WP6La"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**To create linear regression model, and predicetd output**"
      ],
      "metadata": {
        "id": "_Q4yMDUaQfNZ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "lr_model=LinearRegression()\n",
        "lr_model.fit(X_train, y_train)\n",
        "lr_pre=lr_model.predict(X_test)\n"
      ],
      "metadata": {
        "id": "Ckwr9c_fQLYV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "lr_pre=lr_pre.reshape(-1,1)\n",
        "lr_pre_test_set=np.concatenate([lr_pre, X_test], axis=1)\n",
        "lr_pre_test_set=scaler.inverse_transform(lr_pre_test_set)\n",
        "lr_pre_test_set"
      ],
      "metadata": {
        "id": "8oyBBAyeRKZW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "result_list=[]\n",
        "for index in range (0, len(lr_pre_test_set)):\n",
        "  result_list.append(lr_pre_test_set[index][0]+act_sales[index])\n",
        "lr_pre_series=pd.Series(result_list, name=\"Linear Prediction\")\n",
        "predict_df=predict_df.merge(lr_pre_series,left_index=True, right_index=True)\n",
        "predict_df"
      ],
      "metadata": {
        "id": "hqBOvIKKStKx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "lr_mse= np.sqrt(mean_squared_error(predict_df['Linear Prediction'], monthly_sales['sales'][-12:]))\n",
        "#MSE and MAE cost function :updating the values of B0 and B1 iteratively until we get an optimal solution.\n",
        "lr_mae=mean_absolute_error(predict_df['Linear Prediction'], monthly_sales['sales'][-12:])\n",
        "#R-Squared is a number that explains the amount of variation that is explained/captured by the developed model. It always ranges between 0 & 1 . Overall, the higher the value of R-squared, the better the model fits the\n",
        "lr_r2=r2_score(predict_df['Linear Prediction'], monthly_sales['sales'][-12:])\n",
        "print(\"Linear Regression MSE: \",lr_mse)\n",
        "print(\"Linear Regression MAE: \",lr_mae)\n",
        "print(\"Linear Regression R2: \",lr_r2)\n"
      ],
      "metadata": {
        "id": "9w6g94wlkqZ5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Visualization of the prediction against eh actual sales**"
      ],
      "metadata": {
        "id": "qO1CLKVuxjwu"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "plt.figure(figsize=(15,5))\n",
        "#Actual sales\n",
        "plt.plot(monthly_sales['date'], monthly_sales ['sales'])\n",
        "#Predicted sales\n",
        "plt.plot(predict_df['date'], predict_df['Linear Prediction'])\n",
        "plt.xlabel(\"Date\")\n",
        "plt.ylabel(\"Sales\")\n",
        "plt.legend(['Actual Sales','Predicted sales'])\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "lcBurb94xSkF"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}